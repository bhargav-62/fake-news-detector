ğŸ“° Fake News Detection System
ğŸ“Œ Overview

This project aims to detect fake vs. real news articles using both traditional ML models (TF-IDF + Logistic Regression) and state-of-the-art Transformer models (DistilBERT, BERT, RoBERTa).

It was developed as part of the NIT Hackathon, showcasing how Natural Language Processing (NLP) can help combat misinformation.

âš™ï¸ Features

âœ… Data cleaning & preprocessing (stopwords removal, lemmatization, regex filters)

âœ… Train/Validation/Test dataset splits

âœ… Baseline ML model (Logistic Regression with TF-IDF)

âœ… Transformer-based classifiers (DistilBERT, BERT)

âœ… Model evaluation (Accuracy, Precision, Recall, F1-score, Classification Report)

âœ… Visualization (Wordclouds, Label Distribution plots)

âœ… Claim extraction using spaCy

âœ… Final article-level decision (aggregated claim classification)

ğŸ“‚ Project Structure
.
â”œâ”€â”€ data/                         # Original datasets (Fake.csv, True.csv, fake_or_real_news.csv)
â”œâ”€â”€ cleaned_data/                 # Train, Validation, Test splits
â”œâ”€â”€ models/                       # Saved fine-tuned models
â”œâ”€â”€ preprocessing.py              # Data cleaning & preprocessing functions
â”œâ”€â”€ train_distilbert.py           # DistilBERT training script
â”œâ”€â”€ baseline_tfidf.py             # TF-IDF + Logistic Regression baseline
â”œâ”€â”€ inference.py                  # Claim extraction + final article analysis
â””â”€â”€ README.md                     # Project documentation

ğŸ“Š Datasets

## Dataset

The dataset WELFake_Dataset.csv is too large for GitHub.
You can download it from Google Drive here:  
[WELFake_Dataset.csv (233 MB)](https://drive.google.com/file/d/1nZQrvCcy_umMI7nhaTf9wqhY9n3ksNG3/view?usp=drive_link)

**Instructions:**  
After downloading, place the CSV in the same directory as your code before running scripts that need it.

Deployed at:
https://huggingface.co/spaces/Bhargav77/Fake-News
